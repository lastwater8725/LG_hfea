import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt 
import seaborn as sns 

train = pd.read_csv('C:/Users/okpl8/Documents/project_LG/data/train.csv') 
test = pd.read_csv('C:/Users/okpl8/Documents/project_LG/data/test.csv')
submit=pd.read_csv('C:/Users/okpl8/Documents/project_LG/data/sample_submission.csv')

train = train.drop('ID', axis = 1)
test = test.drop('ID', axis = 1)

train.drop(columns=['PGD ì‹œìˆ  ì—¬ë¶€','PGS ì‹œìˆ  ì—¬ë¶€','ë‚œì í•´ë™ ê²½ê³¼ì¼','ë°°ì•„ í•´ë™ ê²½ê³¼ì¼',
            'ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜','ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€'],inplace=True)
test.drop(columns=['PGD ì‹œìˆ  ì—¬ë¶€','PGS ì‹œìˆ  ì—¬ë¶€','ë‚œì í•´ë™ ê²½ê³¼ì¼','ë°°ì•„ í•´ë™ ê²½ê³¼ì¼',
            'ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜','ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€'],inplace=True)

train["íŠ¹ì • ì‹œìˆ  ìœ í˜•"] = train["íŠ¹ì • ì‹œìˆ  ìœ í˜•"].fillna("Unknown").astype(str)
test["íŠ¹ì • ì‹œìˆ  ìœ í˜•"] = test["íŠ¹ì • ì‹œìˆ  ìœ í˜•"].fillna("Unknown").astype(str)

def categorize_treatment(x):
    first_part = x.split(":")[0]  # ì²« ë²ˆì§¸ ê°’ ê°€ì ¸ì˜¤ê¸°

    if first_part == "ICSI":
        return "ICSI"
    elif first_part == "IVF":
        return "IVF"
    elif first_part in ["IUI", "ICI"]:
        return "IUI"
    else:
        return "Unknown"

# âœ… ê·¸ë£¹í™” ì ìš© (train & test)
train["íŠ¹ì • ì‹œìˆ  ìœ í˜•"] = train["íŠ¹ì • ì‹œìˆ  ìœ í˜•"].apply(categorize_treatment)
test["íŠ¹ì • ì‹œìˆ  ìœ í˜•"] = test["íŠ¹ì • ì‹œìˆ  ìœ í˜•"].apply(categorize_treatment)

mode_cols = ["ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€", "ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ", "í•´ë™ ë‚œì ìˆ˜", "ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜", "ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜",
             "ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", "ëŒ€ë¦¬ëª¨ ì—¬ë¶€"]

for col in mode_cols:
    if col in train.columns and col in test.columns:  # trainê³¼ test ëª¨ë‘ í•´ë‹¹ ì»¬ëŸ¼ì´ ìˆì„ ë•Œë§Œ ì‹¤í–‰
        mean_value = train[col].mode()[0]  # ğŸš¨ Train ë°ì´í„°ì˜ ìµœë¹ˆê°’
        train[col] = train[col].fillna(mean_value)  # inplace=False ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
        test[col] = test[col].fillna(mean_value)    # inplace=False ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
    else:
        print(f"ì»¬ëŸ¼ {col}ì´(ê°€) train ë˜ëŠ” test ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        
mode_cols = ["ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€", "ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜", "í•´ë™ëœ ë°°ì•„ ìˆ˜", "ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", "ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€",
             "ë‚œì ì±„ì·¨ ê²½ê³¼ì¼", "ë‚œì í˜¼í•© ê²½ê³¼ì¼","ì €ì¥ëœ ë°°ì•„ ìˆ˜","ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜","ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜", "ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜"]

for col in mode_cols:
    if col in train.columns and col in test.columns:  # trainê³¼ test ëª¨ë‘ í•´ë‹¹ ì»¬ëŸ¼ì´ ìˆì„ ë•Œë§Œ ì‹¤í–‰
        mean_value = train[col].mode()[0]  # ğŸš¨ Train ë°ì´í„°ì˜ ìµœë¹ˆê°’
        train[col] = train[col].fillna(mean_value)  # inplace=False ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
        test[col] = test[col].fillna(mean_value)    # inplace=False ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
    else:
        print(f"ì»¬ëŸ¼ {col}ì´(ê°€) train ë˜ëŠ” test ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        
median_cols = ['ì´ ìƒì„± ë°°ì•„ ìˆ˜','','ì´ì‹ëœ ë°°ì•„ ìˆ˜','ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜','í˜¼í•©ëœ ë‚œì ìˆ˜','íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜','ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼']
for col in median_cols:
    if col in train.columns and col in test.columns:  # trainê³¼ test ëª¨ë‘ í•´ë‹¹ ì»¬ëŸ¼ì´ ìˆì„ ë•Œë§Œ ì‹¤í–‰
        mean_value = train[col].median()  # ğŸš¨ Train ë°ì´í„°ì˜ ì¤‘ì•™ê°’
        train[col] = train[col].fillna(mean_value)  # inplace=False ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
        test[col] = test[col].fillna(mean_value)    # inplace=False ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
    else:
        print(f"ì»¬ëŸ¼ {col}ì´(ê°€) train ë˜ëŠ” test ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        
train.drop(columns=['ë°°ë€ ìœ ë„ ìœ í˜•','ë‚œì ê¸°ì¦ì ë‚˜ì´','ì •ì ê¸°ì¦ì ë‚˜ì´'],inplace=True)
test.drop(columns=['ë°°ë€ ìœ ë„ ìœ í˜•','ë‚œì ê¸°ì¦ì ë‚˜ì´','ì •ì ê¸°ì¦ì ë‚˜ì´'],inplace=True)

train.drop(columns=['ë‚œì ì±„ì·¨ ê²½ê³¼ì¼','ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸','ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸'],inplace=True)
test.drop(columns=['ë‚œì ì±„ì·¨ ê²½ê³¼ì¼','ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸','ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸'],inplace=True)

# ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ  ê·¸ë£¹í™” í•¨ìˆ˜
def categorize_embryo_reason(x):
    if "í˜„ì¬ ì‹œìˆ ìš©" in x:
        return "Current"
    elif "ë°°ì•„ ì €ì¥ìš©" in x:
        return "Storage"
    elif "ê¸°ì¦ìš©" in x:
        return "Donation"
    elif "ë‚œì ì €ì¥ìš©" in x:
        return "Egg Storage"
    elif "ì—°êµ¬ìš©" in x:
        return "Research"
    else:
        return "Unknown"

train["ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ "] = train["ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ "].apply(categorize_embryo_reason)
test["ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ "] = test["ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ "].apply(categorize_embryo_reason)

from sklearn.preprocessing import LabelEncoder

label_col=['ì‹œìˆ  ì‹œê¸° ì½”ë“œ','ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´','ì´ ì‹œìˆ  íšŸìˆ˜','í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜','IVF ì‹œìˆ  íšŸìˆ˜','DI ì‹œìˆ  íšŸìˆ˜',
           'ì´ ì„ì‹  íšŸìˆ˜','IVF ì„ì‹  íšŸìˆ˜','DI ì„ì‹  íšŸìˆ˜','ì´ ì¶œì‚° íšŸìˆ˜','IVF ì¶œì‚° íšŸìˆ˜','DI ì¶œì‚° íšŸìˆ˜']
# Label Encoding

for col in label_col:
    # Label Encoder ìƒì„±
    le = LabelEncoder()
    
    # Train ë°ì´í„°ì— Label Encoding ì ìš©
    train[col] = le.fit_transform(train[col].astype(str))
    
    # Test ë°ì´í„°ì— ë™ì¼í•œ Label Encoding ì ìš©
    test[col] = le.transform(test[col].astype(str))  # Testì—ëŠ” transformë§Œ ì ìš©

# ì¸ì½”ë”© í™•ì¸
print(train[label_col].head())
print(test[label_col].head())

from sklearn.preprocessing import OneHotEncoder

onehot_col=['ì‹œìˆ  ìœ í˜•','íŠ¹ì • ì‹œìˆ  ìœ í˜•','ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ','ë‚œì ì¶œì²˜','ì •ì ì¶œì²˜'] 

# OneHotEncoder ìƒì„±
ohe = OneHotEncoder(sparse_output=False, drop='first')  # drop='first'ëŠ” ë”ë¯¸ ë³€ìˆ˜ í•¨ì • ë°©ì§€

# Train ë°ì´í„°ì— One-Hot Encoding ì ìš©
train_encoded = ohe.fit_transform(train[onehot_col])

# Test ë°ì´í„°ì— ë™ì¼í•œ One-Hot Encoding ì ìš©
test_encoded = ohe.transform(test[onehot_col])

# ì¸ì½”ë”©ëœ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•˜ê³  ê¸°ì¡´ ë°ì´í„°ì™€ í•©ì¹˜ê¸°
train_encoded_df = pd.DataFrame(train_encoded, columns=ohe.get_feature_names_out(onehot_col))
test_encoded_df = pd.DataFrame(test_encoded, columns=ohe.get_feature_names_out(onehot_col))

train = pd.concat([train.drop(columns=onehot_col), train_encoded_df], axis=1)
test = pd.concat([test.drop(columns=onehot_col), test_encoded_df], axis=1)

train.drop(columns=['ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸','IVF ì‹œìˆ  íšŸìˆ˜','IVF ì„ì‹  íšŸìˆ˜','IVF ì¶œì‚° íšŸìˆ˜','ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜',
                    'íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜'],inplace=True)
test.drop(columns=['ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸','IVF ì‹œìˆ  íšŸìˆ˜','IVF ì„ì‹  íšŸìˆ˜','IVF ì¶œì‚° íšŸìˆ˜','ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜',
                    'íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜'],inplace=True)

train.drop(columns=['ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸','DI ì„ì‹  íšŸìˆ˜','DI ì¶œì‚° íšŸìˆ˜','í˜¼í•©ëœ ë‚œì ìˆ˜'],inplace=True)
test.drop(columns=['ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸','DI ì„ì‹  íšŸìˆ˜','DI ì¶œì‚° íšŸìˆ˜','í˜¼í•©ëœ ë‚œì ìˆ˜'],inplace=True)

train.drop(columns=['ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸','ì´ ì‹œìˆ  íšŸìˆ˜','ì´ ì¶œì‚° íšŸìˆ˜','ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜','ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€',
                    'ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€'],inplace=True)
test.drop(columns=['ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸','ì´ ì‹œìˆ  íšŸìˆ˜','ì´ ì¶œì‚° íšŸìˆ˜','ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜','ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€',
                    'ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€'],inplace=True)

# ìƒê´€í–‰ë ¬ ê³„ì‚°
corr_matrix = train.corr()

# ìƒê´€ê´€ê³„ê°€ 0.7 ì´ìƒì¸ ê°’ë§Œ ì„ íƒ (ìê¸° ìì‹ ê³¼ì˜ ìƒê´€ê´€ê³„ ì œì™¸)
high_corr = corr_matrix[(corr_matrix > 0.7) & (corr_matrix < 1)]

# ê²°ê³¼ë¥¼ ë³€ìˆ˜ì™€ í•´ë‹¹ ë³€ìˆ˜ì™€ 0.7 ì´ìƒì¸ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ë¡œ ì¶œë ¥
for col in high_corr.columns:
    related_vars = high_corr[col].dropna()  # ê²°ì¸¡ì¹˜ ì œì™¸
    related_vars = related_vars[related_vars >= 0.7]  # 0.7 ì´ìƒì¸ ê°’ë§Œ ì„ íƒ
    if len(related_vars) > 0:  # ìƒê´€ê´€ê³„ê°€ 0.7 ì´ìƒì¸ ê°’ì´ ìˆì„ ê²½ìš°
        print(f"{col}: {', '.join([f'{var}: {related_vars[var]:.2f}' for var in related_vars.index])}")
        
mode_cols = ["ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€", "ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜", "í•´ë™ëœ ë°°ì•„ ìˆ˜", "ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", "ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€",
             "ë‚œì ì±„ì·¨ ê²½ê³¼ì¼", "ë‚œì í˜¼í•© ê²½ê³¼ì¼","ì €ì¥ëœ ë°°ì•„ ìˆ˜","ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜","ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜", "ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜"]

for col in mode_cols:
    if col in train.columns and col in test.columns:  # trainê³¼ test ëª¨ë‘ í•´ë‹¹ ì»¬ëŸ¼ì´ ìˆì„ ë•Œë§Œ ì‹¤í–‰
        mean_value = train[col].mode()[0]  # ğŸš¨ Train ë°ì´í„°ì˜ ìµœë¹ˆê°’
        train[col] = train[col].fillna(mean_value)  # inplace=False ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
        test[col] = test[col].fillna(mean_value)    # inplace=False ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
    else:
        print(f"ì»¬ëŸ¼ {col}ì´(ê°€) train ë˜ëŠ” test ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        
mode_cols = ["ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€", "ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ", "í•´ë™ ë‚œì ìˆ˜", "ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜", "ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜",
             "ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", "ëŒ€ë¦¬ëª¨ ì—¬ë¶€"]

for col in mode_cols:
    if col in train.columns and col in test.columns:  # trainê³¼ test ëª¨ë‘ í•´ë‹¹ ì»¬ëŸ¼ì´ ìˆì„ ë•Œë§Œ ì‹¤í–‰
        mean_value = train[col].mode()[0]  # ğŸš¨ Train ë°ì´í„°ì˜ ìµœë¹ˆê°’
        train[col] = train[col].fillna(mean_value)  # inplace=False ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
        test[col] = test[col].fillna(mean_value)    # inplace=False ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
    else:
        print(f"ì»¬ëŸ¼ {col}ì´(ê°€) train ë˜ëŠ” test ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        
drop_features = [
    "ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ _Donation", "ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ _Egg Storage", "ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ",
    "ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±", "íŠ¹ì • ì‹œìˆ  ìœ í˜•_IUI", "ë‚œì í˜¼í•© ê²½ê³¼ì¼", "í•´ë™ ë‚œì ìˆ˜",
    "ëŒ€ë¦¬ëª¨ ì—¬ë¶€", "ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ"
]
train.drop(columns=drop_features, inplace=True)
test.drop(columns=drop_features, inplace=True)

from sklearn.model_selection import train_test_split

# âœ… ë°ì´í„° ë¶„í• 
X = train.drop(columns=['ì„ì‹  ì„±ê³µ ì—¬ë¶€'])
y = train['ì„ì‹  ì„±ê³µ ì—¬ë¶€']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score, classification_report, precision_recall_curve


###########################################
# 1. Focal Loss êµ¬í˜„
###########################################
class FocalLoss(nn.Module):
    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        inputs = torch.sigmoid(inputs)  # í™•ë¥  ë³€í™˜
        inputs = inputs[:, 1]  # ğŸ”¥ í´ë˜ìŠ¤ 1ì˜ í™•ë¥ ë§Œ ì‚¬ìš©
        targets = targets.float().view(-1)  # ğŸ”¥ 1D ë²¡í„°ë¡œ ë³€í™˜

        inputs = inputs.clamp(min=1e-7, max=1-1e-7)  # log(0) ë°©ì§€
        BCE_loss = F.binary_cross_entropy(inputs, targets, reduction='none')
        pt = torch.where(targets == 1, inputs, 1 - inputs)  # ì •ë‹µ í™•ë¥  ê³„ì‚°
        loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss
        
        return loss.mean() if self.reduction == 'mean' else loss.sum()
focal_loss = FocalLoss(alpha=0.5, gamma=1.0, reduction='mean')

###########################################
# 2. ë°ì´í„° ì¤€ë¹„
###########################################
# X_train, y_train, X_test, testëŠ” ì´ë¯¸ ì „ì²˜ë¦¬ëœ DataFrameì´ë¼ê³  ê°€ì •
X_train_tab = X_train.values.astype(np.float32)
y_train_tab = y_train.values.astype(np.float32).squeeze()  # 1D ë³€í™˜
X_test_tab = X_test.values.astype(np.float32)
X_submission_tab = test.values.astype(np.float32)  # ì œì¶œìš© test ë°ì´í„°

###########################################
# 3. 5-Fold Stratified CVë¥¼ ì´ìš©í•œ TabNet í•™ìŠµ (GPU ì‚¬ìš©)
###########################################
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
stacking_train_meta_tab = np.zeros((X_train_tab.shape[0], 1))
stacking_test_meta_tab = np.zeros((X_test_tab.shape[0], 1))
stacking_submission_meta_tab = np.zeros((X_submission_tab.shape[0], 1))  # ì œì¶œ ì˜ˆì¸¡ìš©

fold_idx = 0
for train_index, val_index in skf.split(X_train_tab, y_train_tab):
    print(f"\n=== TabNet Fold {fold_idx+1} ===")
    X_train_fold_tab, X_val_fold_tab = X_train_tab[train_index], X_train_tab[val_index]
    y_train_fold_tab, y_val_fold_tab = y_train_tab[train_index], y_train_tab[val_index]

    # TabNetClassifier ìƒì„± (GPU ì‚¬ìš©, focal loss ì ìš©)
    tabnet_clf = TabNetClassifier(
        device_name='cuda',  # GPU ì‚¬ìš© ëª…ì‹œ
        optimizer_params=dict(lr=0.001),
        scheduler_params={"step_size": 6, "gamma": 0.9},
        scheduler_fn=torch.optim.lr_scheduler.StepLR,
        seed=42,
        verbose=1
    )

    # TabNet í•™ìŠµ (loss_fnì— FocalLoss ì§ì ‘ ì§€ì •)
    tabnet_clf.fit(
        X_train_fold_tab, y_train_fold_tab,
        eval_set=[(X_val_fold_tab, y_val_fold_tab)],
        eval_metric=['auc'],
        max_epochs=50,
        patience=10,
        batch_size=128,
        virtual_batch_size=64,
        num_workers=0,
        drop_last=False,
        loss_fn=focal_loss  # ğŸ”¥ Focal Loss ì ìš©
    )

    # ê²€ì¦ Foldì— ëŒ€í•œ ì˜ˆì¸¡ (ë©”íƒ€ ë°ì´í„°ë¡œ ì‚¬ìš©)
    stacking_train_meta_tab[val_index, 0] = tabnet_clf.predict_proba(X_val_fold_tab)[:, 1]

    # X_testì— ëŒ€í•œ ì˜ˆì¸¡ (ê° Fold ì˜ˆì¸¡ì„ í‰ê· )
    stacking_test_meta_tab[:, 0] += tabnet_clf.predict_proba(X_test_tab)[:, 1] / skf.n_splits

    # ì œì¶œìš© test ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ (ê° Fold ì˜ˆì¸¡ì„ í‰ê· )
    stacking_submission_meta_tab[:, 0] += tabnet_clf.predict_proba(X_submission_tab)[:, 1] / skf.n_splits

    fold_idx += 1

###########################################
# 4. TabNet ì„±ëŠ¥ í‰ê°€
###########################################
tabnet_train_roc_auc = roc_auc_score(y_train, stacking_train_meta_tab.ravel())
print(f"\nTabNet Training ROC-AUC: {tabnet_train_roc_auc:.4f}")

tabnet_test_roc_auc = roc_auc_score(y_test, stacking_test_meta_tab.ravel())
print(f"TabNet Test ROC-AUC: {tabnet_test_roc_auc:.4f}")

precision_tab, recall_tab, thresholds_tab = precision_recall_curve(y_test, stacking_test_meta_tab.ravel())
f1_scores_tab = (2 * precision_tab * recall_tab) / (precision_tab + recall_tab + 1e-8)
optimal_threshold_tab = thresholds_tab[np.argmax(f1_scores_tab)]
print(f"TabNet Optimal Threshold: {optimal_threshold_tab:.4f}")

Y_test_pred_tab = (stacking_test_meta_tab.ravel() > optimal_threshold_tab).astype(int)
print("\n=== TabNet Classification Report ===")
print(classification_report(y_test, Y_test_pred_tab))

###########################################
# 5. Kaggle ì œì¶œ íŒŒì¼ ìƒì„± (TabNet)
###########################################
submission_filename = f'./data/submission_tabnet_focal_{tabnet_test_roc_auc:.4f}.csv'
sample_submission = pd.read_csv('./data/sample_submission.csv')
sample_submission['probability'] = stacking_submission_meta_tab.ravel()
sample_submission.to_csv(submission_filename, index=False)
print(f"\nâœ… Submission file saved: {submission_filename}")
